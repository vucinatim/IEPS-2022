# Programming assignment 1 (Crawler)
HTTP downloader and renderer: To retrieve and render a web page.
Data extractor: Minimal functionalities to extract images and hyperlinks.
Duplicate detector: To detect already parsed pages.
URL frontier: A list of URLs waiting to be parsed.
Datastore: To store the data and additional metadata used by the crawler.

## Installation

Create python virtual environment and install requirements.
```
$ python3 -m venv venv
$ source venv/bin/activate
$ pip3 install -r requirements.txt
```

## Set up

Some setup instructions.

## How to run

Some instructions on how to run the crawler.